<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GenHMR vs SOTA Methods</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            padding: 0;
        }
        h1 {
            color: #007bff;
        }
        h2 {
            color: #0056b3;
        }
        p {
            margin: 0 0 10px;
        }
        img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ccc;
            margin-bottom: 20px;
        }
        .caption {
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <h1>GenHMR vs SOTA Methods in 3D Human Mesh Recovery</h1>
    <img src="gmr_sota_final.png" alt="Comparison of SOTA Methods and GenHMR" />
    <p class="caption">Figure: Comparison of SOTA methods (HMR2.0 and TokenHMR) with GenHMR. The errors highlighted by red circles indicate the limitations of SOTA approaches in handling unusual poses or ambiguous scenarios.</p>
    
    <h2>GenHMR: Generative Human Mesh Recovery</h2>
    <p>Human mesh recovery (HMR) from monocular images has predominantly been addressed by deterministic methods that output a single prediction for a given 2D image. However, HMR from a single image is an ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods have attempted to address this by generating and fusing multiple plausible 3D reconstructions, but their performance has often lagged behind deterministic approaches.</p>
    <p>In this paper, we introduce <strong>GenHMR</strong>, a novel generative framework that reformulates monocular HMR as an image-conditioned generative task, explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping process. GenHMR comprises two key components: (1) <strong>a pose tokenizer</strong> that converts 3D human poses into a sequence of discrete tokens in a latent space, and (2) <strong>an image-conditional masked transformer</strong> that learns the probabilistic distributions of the pose tokens, conditioned on the input image prompt along with a randomly masked token sequence.</p>
    <p>During <em>inference</em>, the model samples from the learned conditional distribution to iteratively decode high-confidence pose tokens, thereby reducing 3D reconstruction uncertainties. To further refine the reconstruction, a 2D pose-guided resampling technique is proposed to directly fine-tune the decoded pose tokens in the latent space, which forces the projected 3D body mesh to align with the 2D pose clues. Experiments on benchmark datasets demonstrate that GenHMR significantly outperforms state-of-the-art methods. Our project page is available at <a href="https://anonymous-ai-model.github.io/GenHMR/">this link</a>.</p>
</body>
</html>
